{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch2_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSx8bpC_RBdA",
        "colab_type": "text"
      },
      "source": [
        "Baseline 모델이란? -> 일반적인 머신러닝 파이프라인의 모든 과정을 포함하는 가장 기초 모델\n",
        "\n",
        "Tabular 데이터를 다루는 캐글 경진대회에서의 머신러닝 파이프라인의 일반적 순서\n",
        "1. 데이터 전처리\n",
        "2. 피처 엔지니어링\n",
        "3. 머신러닝 모델 학습\n",
        "4. 테스트 데이터 예측 및 캐글 업로드\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NlQ1Oy3RTUo",
        "colab_type": "text"
      },
      "source": [
        "Baseline 모델을 위한 전처리\n",
        "\n",
        "1. 제품 변수의 결측값 0으로 대체\n",
        "2. 훈련 데이터와 테스트 데이터 통합\n",
        "3. 범주형 데이터는 .factorize()를 통해 Label Encoding을 수행\n",
        "4. 데이터 타입이 object로 표현되는 수치형 데이터는 .unique()를 통해 특이값들을 대체하거나 제거, 정수형 데이터로 변환\n",
        "5. 추후 모델 학습에 사용될 변수 이름을 features 리스트에 미리 담는다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak38Grs3R_ki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPgFYvxfQy2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "\n",
        "np.random.seed(2018)\n",
        "\n",
        "# 데이터를 불러온다.\n",
        "trn = pd.read_csv('/content/drive/My Drive/ML/kaggle/santander_product_recommendation/input/train_ver2.csv')\n",
        "tst = pd.read_csv('/content/drive/My Drive/ML/kaggle/santander_product_recommendation/input/test_ver2.csv')\n",
        "\n",
        "# 데이터 전처리\n",
        "\n",
        "# 제품 변수를 별도로 저장해 놓는다.\n",
        "prods = trn.columns[24:].tolist()\n",
        "\n",
        "# 제품 변수 결측값을 미리 0으로 대체한다.\n",
        "trn[prods] = trn[prods].fillna(0.0).astype(np.int8)\n",
        " \n",
        "# 24개 제품 중 하나도 보유하지 않는 고객 데이터를 제거한다.\n",
        "no_product = trn[prods].sum(axis = 1) == 0\n",
        "trn = trn[~no_product]\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터를 통합한다. 테스트 데이터에 없는 제품 변수는 0으로 채운다.\n",
        "for col in trn.columns[24:]:\n",
        "    tst[col] = 0\n",
        "df = pd.concat([trn, tst], axis = 0)\n",
        "\n",
        "# 학습에 사용할 변수를 담는 list이다.\n",
        "features = []\n",
        "\n",
        "# 범주형 변수를 .factorize() 함수를 통해 label encoding한다.\n",
        "categorical_cols = ['ind_empleado', 'pais_residencia', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada', 'indfall', 'tipodom', 'nomprov', 'segmento']\n",
        "for col in categorical_cols:\n",
        "    df[col], _ = df[col].factorize(na_sentinel=-99)\n",
        "features += categorical_cols\n",
        "\n",
        "# 수치형 변수의 특이값과 결측값을 -99로 대체하고, 정수형으로 변환한다.\n",
        "df['age'].replace(' NA', -99, inplace=True)\n",
        "df['age'] = df['age'].astype(np.int8)\n",
        "\n",
        "df['antiguedad'].replace('     NA', -99, inplace=True)\n",
        "df['antiguedad'] = df['antiguedad'].astype(np.int8)\n",
        "\n",
        "df['renta'].replace('         NA', -99, inplace=True)\n",
        "df['renta'].fillna(-99, inplace=True)\n",
        "df['renta'] = df['renta'].astype(float).astype(np.int8)\n",
        "\n",
        "df['indrel_1mes'].replace('P', 5, inplace=True)\n",
        "df['indrel_1mes'].fillna(-99, inplace=True)\n",
        "df['indrel_1mes'] = df['indrel_1mes'].astype(float).astype(np.int8)\n",
        "\n",
        "# 학습에 사용할 수치형 변수를 features에 추구한다.\n",
        "features += ['age','antiguedad','renta','ind_nuevo','indrel','indrel_1mes','ind_actividad_cliente']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr1q8Z4QTSyn",
        "colab_type": "text"
      },
      "source": [
        "### 피처 엔지니어링 - 파생변수 생성 (딥러닝에서는 많이 쓰지 않는다고 함)\n",
        "\n",
        "1. 결측값은 임시로 -99로 대체 \n",
        "2. 기타 등등은 책 참고\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTwbxkWZTRgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (피쳐 엔지니어링) 두 날짜 변수에서 연도와 월 정보를 추출한다.\n",
        "df['fecha_alta_month'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
        "df['fecha_alta_year'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
        "features += ['fecha_alta_month', 'fecha_alta_year']\n",
        "\n",
        "df['ult_fec_cli_1t_month'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
        "df['ult_fec_cli_1t_year'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
        "features += ['ult_fec_cli_1t_month', 'ult_fec_cli_1t_year']\n",
        "\n",
        "# 그 외 변수의 결측값은 모두 -99로 대체한다.\n",
        "df.fillna(-99, inplace=True)\n",
        "\n",
        "# (피쳐 엔지니어링) lag-1 데이터를 생성한다.\n",
        "# 코드 2-12와 유사한 코드 흐름이다.\n",
        "\n",
        "# 날짜를 숫자로 변환하는 함수이다. 2015-01-28은 1, 2016-06-28은 18로 변환된다\n",
        "def date_to_int(str_date):\n",
        "    Y, M, D = [int(a) for a in str_date.strip().split(\"-\")] \n",
        "    int_date = (int(Y) - 2015) * 12 + int(M)\n",
        "    return int_date\n",
        "\n",
        "# 날짜를 숫자로 변환하여 int_date에 저장한다\n",
        "df['int_date'] = df['fecha_dato'].map(date_to_int).astype(np.int8)\n",
        "\n",
        "# 데이터를 복사하고, int_date 날짜에 1을 더하여 lag를 생성한다. 변수명에 _prev를 추가한다.\n",
        "df_lag = df.copy()\n",
        "df_lag.columns = [col + '_prev' if col not in ['ncodpers', 'int_date'] else col for col in df.columns ]\n",
        "df_lag['int_date'] += 1\n",
        "\n",
        "# 원본 데이터와 lag 데이터를 ncodper와 int_date 기준으로 합친다. Lag 데이터의 int_date는 1 밀려 있기 때문에, 저번 달의 제품 정보가 삽입된다.\n",
        "df_trn = df.merge(df_lag, on=['ncodpers','int_date'], how='left')\n",
        "\n",
        "# 메모리 효율을 위해 불필요한 변수를 메모리에서 제거한다\n",
        "del df, df_lag\n",
        "\n",
        "# 저번 달의 제품 정보가 존재하지 않을 경우를 대비하여 0으로 대체한다.\n",
        "for prod in prods:\n",
        "    prev = prod + '_prev'\n",
        "    df_trn[prev].fillna(0, inplace=True)\n",
        "df_trn.fillna(-99, inplace=True)\n",
        "\n",
        "# lag-1 변수를 추가한다.\n",
        "features += [feature + '_prev' for feature in features]\n",
        "features += [prod + '_prev' for prod in prods]\n",
        "\n",
        "###\n",
        "### Baseline 모델 이후, 다양한 피쳐 엔지니어링을 여기에 추가한다.\n",
        "###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdD8xYVTuHvH",
        "colab_type": "text"
      },
      "source": [
        "### 교차검증\n",
        "\n",
        "1. 어어어어어어어어어어엄청 중요!\n",
        "2. 경진대회 진행 중 참가자는 하루에 최대 5개의 예측 결과물을 캐글에 제출 가능\n",
        "3. 즉, 제한된 횟수 내에서 성능을 올려야하기 때문에 중요중요\n",
        "\n",
        "이 대회에서는 2015-01-28 ~ 2016-05-28, 총 1년 6개월치의 데이터가 훈련 데이터로 제공\n",
        "\n",
        "예측 해야 하는 테스트 데이터는 2016-06-28의 미래 데이터\n",
        "\n",
        "내부 교차 검증 과정에서도 최신 데이터 (2016-05-28)를 검증 데이터로 분리하고 나머지 데이터를 훈련 데이터로 사용하는 것이 일반적\n",
        "\n",
        "Baseline 모델에서는 모델을 간소화하기 위해 2016-01-28 ~ 2016-04-28 총 4개월치 데이터를 훈련 데이터로 사용하고, 2016-05-28 데이터를 검증 데이터로 사용\n",
        "\n",
        "![대체 텍스트](https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F992D944A5AC0B47607)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgfY4vcpuIHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## 모델 학습\n",
        "# 학습을 위하여 데이터를 훈련, 테스트용으로 분리한다.\n",
        "# 학습에는 2016-01-28 ~ 2016-04-28 데이터만 사용하고, 검증에는 2016-05-28 데이터를 사용한다.\n",
        "use_dates = ['2016-01-28', '2016-02-28', '2016-03-28', '2016-04-28', '2016-05-28']\n",
        "trn = df_trn[df_trn['fecha_dato'].isin(use_dates)]\n",
        "tst = df_trn[df_trn['fecha_dato'] == '2016-06-28']\n",
        "del df_trn\n",
        "\n",
        "# 훈련 데이터에서 신규 구매 건수만 추출한다.\n",
        "X = []\n",
        "Y = []\n",
        "for i, prod in enumerate(prods):\n",
        "    prev = prod + '_prev'\n",
        "    prX = trn[(trn[prod] == 1) & (trn[prev] == 0)]\n",
        "    prY = np.zeros(prX.shape[0], dtype=np.int8) + i\n",
        "    X.append(prX)\n",
        "    Y.append(prY)\n",
        "XY = pd.concat(X)\n",
        "Y = np.hstack(Y)\n",
        "XY['y'] = Y\n",
        "\n",
        "# 훈련, 검증 데이터로 분리한다. \n",
        "vld_date = '2016-05-28'\n",
        "XY_trn = XY[XY['fecha_dato'] != vld_date]\n",
        "XY_vld = XY[XY['fecha_dato'] == vld_date]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPc56MkqvxzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# XGBoost 모델 parameter를 설정한다.\n",
        "param = {\n",
        "    'booster': 'gbtree',\n",
        "    'max_depth': 8,\n",
        "    'nthread': 4,\n",
        "    'num_class': len(prods),\n",
        "    'objective': 'multi:softprob',\n",
        "    'silent': 1,\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'eta': 0.1,\n",
        "    'min_child_weight': 10,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'colsample_bylevel': 0.9,\n",
        "    'seed': 2018,\n",
        "    }\n",
        "\n",
        "# 훈련, 검증 데이터를 XGBoost 형태로 변환한다.\n",
        "X_trn = XY_trn.as_matrix(columns=features)\n",
        "Y_trn = XY_trn.as_matrix(columns=['y'])\n",
        "dtrn = xgb.DMatrix(X_trn, label=Y_trn, feature_names=features)\n",
        "\n",
        "X_vld = XY_vld.as_matrix(columns=features)\n",
        "Y_vld = XY_vld.as_matrix(columns=['y'])\n",
        "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\n",
        "\n",
        "# XGBoost 모델을 훈련 데이터로 학습한다!\n",
        "watch_list = [(dtrn, 'train'), (dvld, 'eval')]\n",
        "model = xgb.train(param, dtrn, num_boost_round=1000, evals=watch_list, early_stopping_rounds=20)\n",
        "\n",
        "# 학습한 모델을 저장한다.\n",
        "import pickle\n",
        "pickle.dump(model, open(\"/content/drive/My Drive/ML/kaggle/santander_product_recommendation/input/xgb.baseline.pkl\", \"wb\"))\n",
        "best_ntree_limit = model.best_ntree_limit\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqOlDJQIwZ1j",
        "colab_type": "text"
      },
      "source": [
        "### 교차 검증\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQh02fmdwcOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MAP@7 평가 척도를 위한 준비작업이다.\n",
        "# 고객 식별 번호를 추출한다.\n",
        "vld = trn[trn['fecha_dato'] == vld_date]\n",
        "ncodpers_vld = vld.as_matrix(columns=['ncodpers'])\n",
        "# 검증 데이터에서 신규 구매를 구한다.\n",
        "for prod in prods:\n",
        "    prev = prod + '_prev'\n",
        "    padd = prod + '_add'\n",
        "    vld[padd] = vld[prod] - vld[prev]    \n",
        "add_vld = vld.as_matrix(columns=[prod + '_add' for prod in prods])\n",
        "add_vld_list = [list() for i in range(len(ncodpers_vld))]\n",
        "\n",
        "# 고객별 신규 구매 정답 값을 add_vld_list에 저장하고, 총 count를 count_vld에 저장한다.\n",
        "count_vld = 0\n",
        "for ncodper in range(len(ncodpers_vld)):\n",
        "    for prod in range(len(prods)):\n",
        "        if add_vld[ncodper, prod] > 0:\n",
        "            add_vld_list[ncodper].append(prod)\n",
        "            count_vld += 1\n",
        "\n",
        "# 검증 데이터에서 얻을 수 있는 MAP@7 최고점을 미리 구한다. (0.042663)\n",
        "print(mapk(add_vld_list, add_vld_list, 7, 0.0))\n",
        "\n",
        "# 검증 데이터에 대한 예측 값을 구한다.\n",
        "X_vld = vld.as_matrix(columns=features)\n",
        "Y_vld = vld.as_matrix(columns=['y'])\n",
        "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\n",
        "preds_vld = model.predict(dvld, ntree_limit=best_ntree_limit)\n",
        "\n",
        "# 저번 달에 보유한 제품은 신규 구매가 불가하기 때문에, 확률값에서 미리 1을 빼준다\n",
        "preds_vld = preds_vld - vld.as_matrix(columns=[prod + '_prev' for prod in prods])\n",
        "\n",
        "# 검증 데이터 예측 상위 7개를 추출한다.\n",
        "result_vld = []\n",
        "for ncodper, pred in zip(ncodpers_vld, preds_vld):\n",
        "    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
        "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
        "    result_vld.append([ip for y,p,ip in y_prods])\n",
        "    \n",
        "# 검증 데이터에서의 MAP@7 점수를 구한다. (0.036466)\n",
        "print(mapk(add_vld_list, result_vld, 7, 0.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmpFY2r4xZJy",
        "colab_type": "text"
      },
      "source": [
        "### 테스트 데이터 예측 및 캐글 업로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdHvVxntxZfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# XGBoost 모델을 전체 훈련 데이터로 재학습한다!\n",
        "X_all = XY.as_matrix(columns=features)\n",
        "Y_all = XY.as_matrix(columns=['y'])\n",
        "dall = xgb.DMatrix(X_all, label=Y_all, feature_names=features)\n",
        "watch_list = [(dall, 'train')]\n",
        "# 트리 개수를 늘어난 데이터 양만큼 비례해서 증가한다.\n",
        "best_ntree_limit = int(best_ntree_limit * (len(XY_trn) + len(XY_vld)) / len(XY_trn))\n",
        "# XGBoost 모델 재학습!\n",
        "model = xgb.train(param, dall, num_boost_round=best_ntree_limit, evals=watch_list)\n",
        "\n",
        "# 변수 중요도를 출력해본다. 예상하던 변수가 상위로 올라와 있는가?\n",
        "print(\"Feature importance:\")\n",
        "for kv in sorted([(k,v) for k,v in model.get_fscore().items()], key=lambda kv: kv[1], reverse=True):\n",
        "    print(kv)\n",
        "\n",
        "# 캐글 제출을 위하여 테스트 데이터에 대한 예측 값을 구한다.\n",
        "X_tst = tst.as_matrix(columns=features)\n",
        "dtst = xgb.DMatrix(X_tst, feature_names=features)\n",
        "preds_tst = model.predict(dtst, ntree_limit=best_ntree_limit)\n",
        "ncodpers_tst = tst.as_matrix(columns=['ncodpers'])\n",
        "preds_tst = preds_tst - tst.as_matrix(columns=[prod + '_prev' for prod in prods])\n",
        "\n",
        "# 제출 파일을 생성한다.\n",
        "submit_file = open('../model/xgb.baseline.2015-06-28', 'w')\n",
        "submit_file.write('ncodpers,added_products\\n')\n",
        "for ncodper, pred in zip(ncodpers_tst, preds_tst):\n",
        "    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
        "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
        "    y_prods = [p for y,p,ip in y_prods]\n",
        "    submit_file.write('{},{}\\n'.format(int(ncodper), ' '.join(y_prods)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}